{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s6Oi4OFtlMFM"
   },
   "source": [
    "# CNN + Glove + BiLSTM + CRF model for Entity Extraction on CoNLL 03\n",
    "\n",
    "In this notebook, we implement the neural network model described in [this paper](https://www.aclweb.org/anthology/P16-1101.pdf). This model is composed of:\n",
    "* A CNN that extracts morphological character-level features;\n",
    "* Glove 100-dimensional 6B embedding for word-level information;\n",
    "* A BiLSTM and a CRF layers for predictions.\n",
    "\n",
    "Data preprocessing is composed of padding sentences plus token encoding and character-sequences padding to fixed length. Then, we implement this model using `tensorflow.keras` and the `tf2crf` package for a CRF layer compatible with tensorflow. We test it on the CoNLL03 english dataset, using the `seqeval` package for f1-score evaluation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-nmzyeF3u_Ni"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from utils import dataio, kerasutils, modelutils\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from seqeval.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RzksTlOXmRrW"
   },
   "source": [
    "## Load Dataset\n",
    "We load CONLL2003 dataset from [this GitHub repo](https://github.com/davidsbatista/NER-datasets/tree/master/CONLL2003). \n",
    "For each token we keep only the string of the word and and the Entity tag (in BIO notation), we discard PoS and Dependency tags. One token per line, features separated with a whitespace, sentences are separated with an empty line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "lyW9pOkIyCE-",
    "outputId": "86507bba-e635-4cd1-fcb0-bffb1fe0a8e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file data\\conll03\\train.txt\n",
      "Read 14027 sentences\n",
      "Reading file data\\conll03\\valid.txt\n",
      "Read 3249 sentences\n",
      "Reading file data\\conll03\\test.txt\n",
      "Read 3452 sentences\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.join('data', 'conll03')\n",
    "raw_train, ner_train, output_labels = dataio.load_conll_data('train.txt', dir_path=data_dir, only_tokens=True)\n",
    "raw_valid, ner_valid, _ = dataio.load_conll_data('valid.txt', dir_path=data_dir, only_tokens=True)\n",
    "raw_test, ner_test, _ = dataio.load_conll_data('test.txt', dir_path=data_dir, only_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "geqnMdyGowtw",
    "outputId": "159f0dfe-c190-489a-dc6d-c7999f68c7cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: {'B-PER', 'I-MISC', 'I-PER', 'B-LOC', 'B-MISC', 'I-LOC', 'I-ORG', 'B-ORG', 'O'}\n"
     ]
    }
   ],
   "source": [
    "print('Labels:', output_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "geqnMdyGowtw",
    "outputId": "159f0dfe-c190-489a-dc6d-c7999f68c7cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Example:\n",
      "German   |  B-MISC\n",
      "call     |  O\n",
      "to       |  O\n",
      "boycott  |  O\n",
      "British  |  B-MISC\n",
      "lamb     |  O\n",
      ".        |  O\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentence Example:\")\n",
    "for i in range(len(raw_train[0])):\n",
    "    print(f'{raw_train[0][i]:7}  |  {ner_train[0][i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "opnm9IMny5ID"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kjmchvML7JWw"
   },
   "source": [
    "# Data Preparation\n",
    "Prepare character- and word-level input for the model.\n",
    "\n",
    "## Sentence encoding and padding\n",
    "We use a Keras `Tokenizer` to extract the vocabulary and encode words. We pad sentences to a fixed length because it is required from LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mgkojyV47DDQ"
   },
   "outputs": [],
   "source": [
    "# integer encode sequences of words\n",
    "token_tokenizer = Tokenizer()    # Automatically lowers tokens\n",
    "token_tokenizer.fit_on_texts(raw_train + raw_valid + raw_test)\n",
    "train_sequences = token_tokenizer.texts_to_sequences(raw_train)\n",
    "test_sequences = token_tokenizer.texts_to_sequences(raw_test)\n",
    "valid_sequences = token_tokenizer.texts_to_sequences(raw_valid)\n",
    "\n",
    "# Label encoding\n",
    "tag2idx = { tag: idx for idx, tag in enumerate(output_labels) }\n",
    "idx2tag = { idx: tag for tag, idx in tag2idx.items() }\n",
    "ner_train_sequences = [[tag2idx[tag] for tag in sentence] for sentence in ner_train]\n",
    "ner_test_sequences  = [[tag2idx[tag] for tag in sentence] for sentence in ner_test ]\n",
    "ner_valid_sequences = [[tag2idx[tag] for tag in sentence] for sentence in ner_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HVOgrGyg5D06",
    "outputId": "b764bd2b-3e1c-4fa6-c455-c5087e8b35c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26861\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = len(token_tokenizer.word_counts)\n",
    "print(vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XhUgVKH85GU_"
   },
   "outputs": [],
   "source": [
    "max_sentence_len = 50\n",
    "\n",
    "# Sentence padding\n",
    "X_sent_train = pad_sequences(train_sequences, maxlen=max_sentence_len, padding='post', truncating='post')\n",
    "X_sent_test = pad_sequences(test_sequences, maxlen=max_sentence_len, padding='post', truncating='post')\n",
    "X_sent_valid = pad_sequences(valid_sequences, maxlen=max_sentence_len, padding='post', truncating='post')\n",
    "\n",
    "Y_train = pad_sequences(ner_train_sequences, maxlen=max_sentence_len, value=tag2idx['O'], padding='post', truncating='post')\n",
    "Y_test = pad_sequences(ner_test_sequences, maxlen=max_sentence_len, value=tag2idx['O'], padding='post', truncating='post')\n",
    "Y_valid = pad_sequences(ner_valid_sequences, maxlen=max_sentence_len, value=tag2idx['O'], padding='post', truncating='post')\n",
    "\n",
    "X_sent_train = np.array(X_sent_train)\n",
    "Y_train = np.array(Y_train)\n",
    "X_sent_test = np.array(X_sent_test)\n",
    "Y_test = np.array(Y_test)\n",
    "X_sent_valid = np.array(X_sent_valid)\n",
    "Y_valid = np.array(Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "TYX5wdr75Zp-",
    "outputId": "5a204f82-2574-4aa6-c07a-14548b4f93ab"
   },
   "outputs": [],
   "source": [
    "token_tokenizer.index_word[0] = '_PAD_'\n",
    "token_tokenizer.word_index['_PAD_'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "TYX5wdr75Zp-",
    "outputId": "5a204f82-2574-4aa6-c07a-14548b4f93ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded and padded sentence:\n",
      "   207 | german\n",
      "   709 | call\n",
      "     6 | to\n",
      "  3628 | boycott\n",
      "   228 | british\n",
      "  7656 | lamb\n",
      "     3 | .\n",
      "     0 | _PAD_\n",
      "     0 | _PAD_\n",
      "     0 | _PAD_\n",
      "     0 | _PAD_\n",
      "     0 | _PAD_\n",
      "     0 | _PAD_\n",
      "     0 | _PAD_\n",
      "     0 | _PAD_\n",
      "     0 | _PAD_\n",
      "     0 | _PAD_\n",
      "     0 | _PAD_\n",
      "     0 | _PAD_\n",
      "     0 | _PAD_\n"
     ]
    }
   ],
   "source": [
    "print('Encoded and padded sentence:')\n",
    "for i in range(len(X_sent_train[0][:20])):\n",
    "    print(f'{X_sent_train[0][i]:6} | {token_tokenizer.index_word[X_sent_train[0][i]]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t3FaEIl15nvp"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RwKih7le7Oic"
   },
   "source": [
    "## Character encoding and padding\n",
    "In order to extract character-level informations, we have to:\n",
    "* Encode characters with integers;\n",
    "* Pad words to a fixed lengths;\n",
    "* Use the 0 as padding code both for sentence padding and for word padding.\n",
    "\n",
    "We don't want to truncate words because prefix and suffix contains precious informations, so we take the longest word and we pad words to its length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yENsgixv-kmm"
   },
   "outputs": [],
   "source": [
    "def to_char_list(data):\n",
    "    '''Transform all the words of a dataset into lists of characters'''\n",
    "    \n",
    "    char_data = []\n",
    "    for sentence in data:\n",
    "        char_sent = []\n",
    "        for word in sentence:\n",
    "            char_sent.append(list(word))\n",
    "        char_data.append(char_sent)\n",
    "    return char_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "ISB3Hepk5Yro",
    "outputId": "e3d2cc7b-7c9d-4de1-e263-91c51345ebc2"
   },
   "outputs": [],
   "source": [
    "raw_char_train = to_char_list(raw_train)\n",
    "raw_char_test = to_char_list(raw_test)\n",
    "raw_char_valid = to_char_list(raw_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "ISB3Hepk5Yro",
    "outputId": "e3d2cc7b-7c9d-4de1-e263-91c51345ebc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence as char lists:\n",
      "['G', 'e', 'r', 'm', 'a', 'n']\n",
      "['c', 'a', 'l', 'l']\n",
      "['t', 'o']\n",
      "['b', 'o', 'y', 'c', 'o', 't', 't']\n",
      "['B', 'r', 'i', 't', 'i', 's', 'h']\n",
      "['l', 'a', 'm', 'b']\n",
      "['.']\n",
      "==============================\n",
      "14027\n"
     ]
    }
   ],
   "source": [
    "print('Sentence as char lists:')\n",
    "for token in raw_char_train[0]:\n",
    "    print(token)\n",
    "print('='*30)\n",
    "print(len(raw_char_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LRBCQI7DwudX"
   },
   "outputs": [],
   "source": [
    "# Sanity check of preprocessed data dimensions. If it does not output anything,\n",
    "# everything is fine.\n",
    "for sent_idx in range(len(raw_train)):\n",
    "    if len(raw_char_train[sent_idx]) != len(train_sequences[sent_idx]):\n",
    "        print('sequence len error')\n",
    "        print(raw_char_train[sent_idx])\n",
    "        print(train_sequences[sent_idx])\n",
    "    for word_idx in range(len(raw_train[sent_idx])):\n",
    "        if len(raw_char_train[sent_idx][word_idx]) != len(raw_train[sent_idx][word_idx]):\n",
    "            print('word len error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Character vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "OL9BX1ZEK2RN",
    "outputId": "e714327e-05b6-4679-ca82-07942de92ed2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charset dimension: 94\n",
      "Charset: abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "# NOTE: Tokenizer may take an argument char_level=True. We should try it in \n",
    "# order to get a cleaner code, but in this way we do not have a fixed length\n",
    "# for words.\n",
    "char_tokenizer = Tokenizer(lower=False, filters='')\n",
    "# Build a list with all the characters\n",
    "charset = string.ascii_letters + string.digits + string.punctuation\n",
    "print(f'Charset dimension: {len(charset)}')\n",
    "print(f'Charset: {charset}')\n",
    "char_tokenizer.fit_on_texts(list(charset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u-i2B1_xMp1y"
   },
   "outputs": [],
   "source": [
    "# Add padding to the tokenizer with the 0 integer encoding\n",
    "char_tokenizer.index_word[0] = '_PAD_'\n",
    "char_tokenizer.word_index['_PAD_'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y68BSHYmM9-B"
   },
   "source": [
    "#### Pad sentences\n",
    "Set the lengths to `max_sentence_len` (50) with padding and truncate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "vE54ewxXM3XD",
    "outputId": "4f11bf5e-3f98-460c-bbfd-e8ff7c80f168"
   },
   "outputs": [],
   "source": [
    "for dataset in [raw_char_train, raw_char_test, raw_char_valid]:\n",
    "    for sent_idx in range(len(dataset)):\n",
    "        if len(dataset[sent_idx]) > max_sentence_len:\n",
    "            # Truncate long sentences\n",
    "            dataset[sent_idx] = dataset[sent_idx][:max_sentence_len]\n",
    "        while len(dataset[sent_idx]) < max_sentence_len:\n",
    "            # Pad sentences with '_PAD_' characters\n",
    "            # ATTENTION: we are not adding the padding tokens of sentence \n",
    "            # padding. We add padding tokens made by a single padding character\n",
    "            pad_word = []\n",
    "            pad_word.append(char_tokenizer.index_word[0])\n",
    "            dataset[sent_idx].append(pad_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "vE54ewxXM3XD",
    "outputId": "4f11bf5e-3f98-460c-bbfd-e8ff7c80f168"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded sentence:\n",
      "['G', 'e', 'r', 'm', 'a', 'n']\n",
      "['c', 'a', 'l', 'l']\n",
      "['t', 'o']\n",
      "['b', 'o', 'y', 'c', 'o', 't', 't']\n",
      "['B', 'r', 'i', 't', 'i', 's', 'h']\n",
      "['l', 'a', 'm', 'b']\n",
      "['.']\n",
      "['_PAD_']\n",
      "['_PAD_']\n",
      "['_PAD_']\n",
      "['_PAD_']\n",
      "['_PAD_']\n",
      "['_PAD_']\n",
      "['_PAD_']\n",
      "['_PAD_']\n",
      "['_PAD_']\n",
      "['_PAD_']\n",
      "['_PAD_']\n",
      "['_PAD_']\n",
      "['_PAD_']\n"
     ]
    }
   ],
   "source": [
    "print('Padded sentence:')\n",
    "for token in raw_char_train[0][:20]:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hA6-2tB9NsuI",
    "outputId": "d5c44943-d589-4132-ae3f-83116642b1ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(char_tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZmFx1qRLoP5G"
   },
   "source": [
    "#### Encode characters with integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wF5ykXXaoceE"
   },
   "outputs": [],
   "source": [
    "char_seq_train = []\n",
    "for sentence in raw_char_train:\n",
    "    char_seq_train.append(char_tokenizer.texts_to_sequences(sentence))\n",
    "\n",
    "char_seq_test = []\n",
    "for sentence in raw_char_test:\n",
    "    char_seq_test.append(char_tokenizer.texts_to_sequences(sentence))\n",
    "\n",
    "char_seq_valid = []\n",
    "for sentence in raw_char_valid:\n",
    "    char_seq_valid.append(char_tokenizer.texts_to_sequences(sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A human unfriendly encoded sentence:\n",
      "[[33, 5, 18, 13, 1, 14], [3, 1, 12, 12], [20, 15], [2, 15, 25, 3, 15, 20, 20], [28, 18, 9, 20, 9, 19, 8], [12, 1, 13, 2], [76], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0]]\n"
     ]
    }
   ],
   "source": [
    "print('A human unfriendly encoded sentence:')\n",
    "print(char_seq_train[0][:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UkFWAk6IOV-v"
   },
   "source": [
    "#### Pad words \n",
    "Set all the words to max_word_len with padding and (possibly without) truncate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ONfUhZcHOVem"
   },
   "outputs": [],
   "source": [
    "def pad_words(sentence, maxlen, pad=0):\n",
    "    padded_sentence = []\n",
    "    for word in sentence:\n",
    "        new_word = word.copy()\n",
    "        if len(word) > maxlen:\n",
    "            new_word = word[:maxlen]\n",
    "        else:\n",
    "            while maxlen - len(new_word) > 1:\n",
    "                new_word.append(pad)\n",
    "                new_word.insert(0, pad)\n",
    "            if maxlen - len(new_word) == 1:\n",
    "                new_word.insert(0, pad)\n",
    "        padded_sentence.append(new_word)\n",
    "    \n",
    "    return padded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zu6KDDBuO-Yf",
    "outputId": "96a1e8d9-75d0-4500-ed37-51668e1d530d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word length: 52\n"
     ]
    }
   ],
   "source": [
    "max_word_len = max([len(word) for word in token_tokenizer.word_index.keys()])\n",
    "print('Word length:', max_word_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PqbkIqVCvlKM"
   },
   "outputs": [],
   "source": [
    "X_char_train = np.array([pad_words(sentence, maxlen=max_word_len) for sentence in char_seq_train])\n",
    "X_char_test  = np.array([pad_words(sentence, maxlen=max_word_len) for sentence in char_seq_test ])\n",
    "X_char_valid = np.array([pad_words(sentence, maxlen=max_word_len) for sentence in char_seq_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "71a_wGIny7BW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0 33  5 18 13  1 14  0  0  0]\n",
      "['_PAD_', '_PAD_', '_PAD_', 'G', 'e', 'r', 'm', 'a', 'n', '_PAD_', '_PAD_', '_PAD_']\n",
      "==============================\n",
      "[ 0  0  0  0  3  1 12 12  0  0  0  0]\n",
      "['_PAD_', '_PAD_', '_PAD_', '_PAD_', 'c', 'a', 'l', 'l', '_PAD_', '_PAD_', '_PAD_', '_PAD_']\n",
      "==============================\n",
      "[ 0  0  0  0  0 20 15  0  0  0  0  0]\n",
      "['_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', 't', 'o', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_']\n",
      "==============================\n",
      "[ 0  0  0  2 15 25  3 15 20 20  0  0]\n",
      "['_PAD_', '_PAD_', '_PAD_', 'b', 'o', 'y', 'c', 'o', 't', 't', '_PAD_', '_PAD_']\n",
      "==============================\n",
      "[ 0  0  0 28 18  9 20  9 19  8  0  0]\n",
      "['_PAD_', '_PAD_', '_PAD_', 'B', 'r', 'i', 't', 'i', 's', 'h', '_PAD_', '_PAD_']\n",
      "==============================\n",
      "[ 0  0  0  0 12  1 13  2  0  0  0  0]\n",
      "['_PAD_', '_PAD_', '_PAD_', '_PAD_', 'l', 'a', 'm', 'b', '_PAD_', '_PAD_', '_PAD_', '_PAD_']\n",
      "==============================\n",
      "[ 0  0  0  0  0  0 76  0  0  0  0  0]\n",
      "['_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '.', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_']\n",
      "==============================\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "['_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_']\n",
      "==============================\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "['_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_']\n",
      "==============================\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "['_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_']\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "for word in X_char_train[0][:10]:\n",
    "    print(word[20:32])\n",
    "    print([char_tokenizer.index_word[char] for char in word[20:32]])\n",
    "    print('='*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F_TnLzE3Pp-W"
   },
   "outputs": [],
   "source": [
    "# Sanity check of preprocessed data dimensions. If it does not output anything,\n",
    "# everything is fine.\n",
    "for sentence in X_char_train:\n",
    "    if len(sentence) != max_sentence_len:\n",
    "        print('sentence error')\n",
    "    for word in sentence:\n",
    "        if len(word) != max_word_len:\n",
    "            print(f'word error: {len(word)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V3fqZ0_opkhx"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bXVl5Praplz4"
   },
   "source": [
    "# Model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bWXt5ji7xmRD"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, TimeDistributed, Dropout, Input, \\\n",
    "    MaxPooling1D, Flatten, concatenate, Bidirectional, LSTM, Dense\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tf2crf import CRF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "73W5p2gcJ5kb"
   },
   "source": [
    "#### Hyperparameters of the model\n",
    "You can choose between the parametrization of two proposed models:\n",
    "* Ma, Xuezhe, and Eduard Hovy. \"End-to-end sequence labeling via bi-directional lstm-cnns-crf.\" *arXiv preprint arXiv:1603.01354* (2016).\n",
    "* Chiu, Jason PC, and Eric Nichols. \"Named entity recognition with bidirectional LSTM-CNNs.\" *Transactions of the Association for Computational Linguistics 4* (2016): 357-370.\n",
    "The first works better, but it may be because second originally included the use of additional word features that we don't consider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CHIU_CONFIG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dywNEZQjpjxo"
   },
   "outputs": [],
   "source": [
    "if USE_CHIU_CONFIG:\n",
    "    char_embedding_dim = 25\n",
    "    cnn_window_size = 3\n",
    "    cnn_filters_number = 53\n",
    "\n",
    "    word_embedding_dim = 100\n",
    "    hidden_cells = 275\n",
    "    drop=0.68\n",
    "\n",
    "    batch_size = 9\n",
    "    epochs = 80\n",
    "else:\n",
    "    char_embedding_dim = 30\n",
    "    cnn_window_size = 3\n",
    "    cnn_filters_number = 30\n",
    "\n",
    "    word_embedding_dim = 100\n",
    "    hidden_cells = 200\n",
    "    drop=0.5\n",
    "\n",
    "    batch_size = 10\n",
    "    epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "iop9KKVsBdkN",
    "outputId": "9701b9e3-8859-4412-c616-4564b842cfc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence token length: 50\n",
      "Word character length: 52\n"
     ]
    }
   ],
   "source": [
    "print('Sentence token length:', max_sentence_len)\n",
    "print('Word character length:', max_word_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zmnpU7dNtTj-"
   },
   "source": [
    "## CNN\n",
    "We use a Convolutional Neural Network to extract pattern information from the characters of the word. The CNN architecture is composed by:\n",
    "* A `keras.layers.Embedding` layer, which is a lookup table that associate a vector to each character;\n",
    "* A 1-dimensional convolution on the embedding vectors in order to capture character-level information;\n",
    "* A MaxPool1d that transforms a series of vectors in a unique vectors which contains informations from the characters of the word. \n",
    "\n",
    "Credits to the author of [this repo](https://github.com/kamalkraj/Named-Entity-Recognition-with-Bidirectional-LSTM-CNNs/blob/master/nn.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KMJjHLHXw3KK"
   },
   "outputs": [],
   "source": [
    "cnn_input = Input(shape=(max_sentence_len, max_word_len,), name='char_encoding')\n",
    "# We use TimeDistributed layer because we have two level of sequences:\n",
    "# * The sentence is a sequence of words;\n",
    "# * The word is a sequence of characters;\n",
    "# We want to work on the lowest sequence. the sequence of characters, so the\n",
    "# TimeDistributed layer allow us to apply this model to each word. We cannot \n",
    "# use mask_zero=True in the Embedding because the cnn1d does not support masking.\n",
    "cnn = TimeDistributed(Embedding(len(char_tokenizer.word_index), char_embedding_dim), name='cnn_Embedding')(cnn_input)\n",
    "cnn = Dropout(drop)(cnn)\n",
    "cnn = TimeDistributed(Conv1D(filters=cnn_filters_number, kernel_size=cnn_window_size, padding='same'), name='cnn_Convolution1d')(cnn)\n",
    "cnn = TimeDistributed(MaxPooling1D(max_word_len), name='cnn_MaxPooling1d')(cnn)\n",
    "# We finally obtain a 30-dimensional vector for each word which contains \n",
    "# char-level informations!\n",
    "cnn_out = TimeDistributed(Flatten(), name='cnn_Flatten')(cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uI79cLjoHK4i"
   },
   "source": [
    "## Glove\n",
    "We load Glove embedding in order to embed tokens and capture word-level informations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lc1MVNBEptQ7",
    "outputId": "3b4323da-1aac-4138-bf7c-c43fd8919863"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400001 word vectors.\n"
     ]
    }
   ],
   "source": [
    "glove_embedding_path = os.path.join('embeddings', 'glove.6B.100d.txt')\n",
    "embedding_matrix = kerasutils.load_glove_embedding_matrix(glove_embedding_path, token_tokenizer.word_index, word_embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uTGqWRvULQOZ"
   },
   "outputs": [],
   "source": [
    "word_input = Input(shape=(max_sentence_len,), name='word_encoding')\n",
    "word_embed = Embedding(len(token_tokenizer.word_index)+1, word_embedding_dim, \n",
    "                       weights=[embedding_matrix], input_length=max_sentence_len,\n",
    "                       trainable=True, mask_zero=True, \n",
    "                       name='Glove_Embedding')(word_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sJL8K7CkK9XZ"
   },
   "source": [
    "# BiLSTM + CRF\n",
    "We concatenate character- and word-level informations and pass it to a bidirectional LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S-gjEgMfK8oL"
   },
   "outputs": [],
   "source": [
    "x = concatenate([word_embed, cnn_out], axis=-1)\n",
    "x = Dropout(drop)(x)\n",
    "x = Bidirectional(LSTM(hidden_cells, return_sequences=True, dropout=drop))(x)\n",
    "x = Dense(len(output_labels), activation='relu', name='Dense_Layer')(x)\n",
    "crf = CRF(len(output_labels), dtype='float32', name='CRF_Layer')\n",
    "out = crf(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bvj86RdcyAFv"
   },
   "outputs": [],
   "source": [
    "model = Model(\n",
    "    inputs=[cnn_input, word_input],\n",
    "    outputs=out\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 605
    },
    "colab_type": "code",
    "id": "hR-_OjLb1Xk0",
    "outputId": "1d3b5c2f-3a9c-4511-ea32-385590ece220"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_encoding (InputLayer)      [(None, 50, 52)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cnn_Embedding (TimeDistributed) (None, 50, 52, 30)   2850        char_encoding[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 50, 52, 30)   0           cnn_Embedding[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "cnn_Convolution1d (TimeDistribu (None, 50, 52, 30)   2730        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "word_encoding (InputLayer)      [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cnn_MaxPooling1d (TimeDistribut (None, 50, 1, 30)    0           cnn_Convolution1d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Glove_Embedding (Embedding)     (None, 50, 100)      2686300     word_encoding[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "cnn_Flatten (TimeDistributed)   (None, 50, 30)       0           cnn_MaxPooling1d[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 50, 130)      0           Glove_Embedding[0][0]            \n",
      "                                                                 cnn_Flatten[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 50, 130)      0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 50, 400)      529600      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Dense_Layer (Dense)             (None, 50, 9)        3609        bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "CRF_Layer (CRF)                 (None, 50)           81          Dense_Layer[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 3,225,170\n",
      "Trainable params: 3,225,170\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=crf.loss, \n",
    "    optimizer='adam',\n",
    "    metrics=[crf.accuracy]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BliGFagr3tNE"
   },
   "outputs": [],
   "source": [
    "# Early stopping\n",
    "early_stopping_callback = EarlyStopping(monitor=\"val_loss\",\n",
    "                                        patience=3, min_delta=0.001, verbose=1, \n",
    "                                        restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 689
    },
    "colab_type": "code",
    "id": "4m1DOCgVHgom",
    "outputId": "e9d09231-c5f1-4cf7-fbca-6b62a130681a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1403/1403 [==============================] - 147s 105ms/step - loss: 1.2395 - accuracy: 0.9169 - val_loss: 5.5712 - val_accuracy: 0.9736\n",
      "Epoch 2/20\n",
      "1403/1403 [==============================] - 142s 101ms/step - loss: 0.4641 - accuracy: 0.9637 - val_loss: 5.1270 - val_accuracy: 0.9787\n",
      "Epoch 3/20\n",
      "1403/1403 [==============================] - 136s 97ms/step - loss: 0.3272 - accuracy: 0.9734 - val_loss: 4.9470 - val_accuracy: 0.9825\n",
      "Epoch 4/20\n",
      "1403/1403 [==============================] - 134s 95ms/step - loss: 0.2580 - accuracy: 0.9777 - val_loss: 4.8892 - val_accuracy: 0.9837\n",
      "Epoch 5/20\n",
      "1403/1403 [==============================] - 133s 95ms/step - loss: 0.2144 - accuracy: 0.9812 - val_loss: 4.9278 - val_accuracy: 0.9851\n",
      "Epoch 6/20\n",
      "1403/1403 [==============================] - 131s 94ms/step - loss: 0.1829 - accuracy: 0.9837 - val_loss: 4.9771 - val_accuracy: 0.98571 - ETA: 0s - loss: 0.1830 - accuracy\n",
      "Epoch 7/20\n",
      "1403/1403 [==============================] - ETA: 0s - loss: 0.1601 - accuracy: 0.9853Restoring model weights from the end of the best epoch.\n",
      "1403/1403 [==============================] - 132s 94ms/step - loss: 0.1601 - accuracy: 0.9853 - val_loss: 5.0468 - val_accuracy: 0.9867\n",
      "Epoch 00007: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_char_train, X_sent_train],\n",
    "    Y_train, \n",
    "    batch_size=batch_size, \n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping_callback],\n",
    "    validation_data=({'char_encoding': X_char_valid, 'word_encoding': X_sent_valid}, Y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gg3qkwMFhaEB"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yYvfaGaVhb5-"
   },
   "source": [
    "## Evaluation\n",
    "We evaluate three aspects of the model:\n",
    "* **Memory consumption** using the `kerasutils.print_model_memory_usage()` function (found [here](https://stackoverflow.com/questions/43137288/how-to-determine-needed-memory-of-keras-model));\n",
    "* **Latency in prediction** using the function `time.process_time()`;\n",
    "* **F1-score** _on entities_ on the test set using `seqeval`;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qH5-b5wRXRpx",
    "outputId": "7686d741-d915-423f-88f7-5a3963bef76e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 22.914 MB\n"
     ]
    }
   ],
   "source": [
    "kerasutils.print_model_memory_usage(batch_size, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XjCR4W95Xa2l",
    "outputId": "0343233e-f9b7-47f4-e679-d41c209d0cd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model latency in predictions: 0.00679 s\n"
     ]
    }
   ],
   "source": [
    "lat = modelutils.compute_prediction_latency(\n",
    "    {'char_encoding': X_char_test, 'word_encoding': X_sent_test}, \n",
    "    model, \n",
    "    n_instances=len(X_sent_test)\n",
    ")\n",
    "print(f'Model latency in predictions: {lat:.3} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 924
    },
    "colab_type": "code",
    "id": "GjTgiaPWX96F",
    "outputId": "98ce18a5-5d8c-495e-d4f0-e4ecc4eb394d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set\n",
      "           precision    recall  f1-score   support\n",
      "\n",
      "      PER      0.960     0.986     0.973      6589\n",
      "      LOC      0.934     0.965     0.949      7134\n",
      "     MISC      0.948     0.848     0.896      3435\n",
      "      ORG      0.916     0.930     0.923      6312\n",
      "\n",
      "micro avg      0.938     0.944     0.941     23470\n",
      "macro avg      0.939     0.944     0.941     23470\n",
      "\n",
      "\n",
      "\n",
      "Test Set\n",
      "           precision    recall  f1-score   support\n",
      "\n",
      "      LOC      0.846     0.929     0.885      1655\n",
      "      PER      0.933     0.949     0.941      1579\n",
      "     MISC      0.796     0.707     0.749       700\n",
      "      ORG      0.856     0.847     0.851      1657\n",
      "\n",
      "micro avg      0.868     0.882     0.875      5591\n",
      "macro avg      0.867     0.882     0.874      5591\n",
      "\n",
      "\n",
      "\n",
      "Validation Set\n",
      "           precision    recall  f1-score   support\n",
      "\n",
      "      LOC      0.913     0.959     0.936      1834\n",
      "     MISC      0.920     0.799     0.855       919\n",
      "      PER      0.931     0.968     0.949      1796\n",
      "      ORG      0.883     0.886     0.885      1338\n",
      "\n",
      "micro avg      0.913     0.920     0.917      5887\n",
      "macro avg      0.913     0.920     0.916      5887\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasets = [('Training Set', X_char_train, X_sent_train, Y_train), \n",
    "            ('Test Set', X_char_test, X_sent_test, Y_test), \n",
    "            ('Validation Set', X_char_valid, X_sent_valid, Y_valid)]\n",
    "\n",
    "for title, X_char, X_sent, Y in datasets:\n",
    "    Y_pred = model.predict({'char_encoding': X_char, 'word_encoding': X_sent}, batch_size=batch_size)\n",
    "    # Remove padding\n",
    "    Y, Y_pred = kerasutils.remove_seq_padding(X_sent, Y, Y_pred)\n",
    "    # Transform label ids in label strings\n",
    "    Y, Y_pred = modelutils.from_encode_to_literal_labels(Y, Y_pred, idx2tag)\n",
    "    print(title)\n",
    "    print(classification_report(Y, Y_pred, digits=3))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      TOKEN      TRUE Y | PRED Y\n",
      "==================================\n",
      "japan            B-LOC  | B-LOC\n",
      "get              O      | O\n",
      "lucky            O      | O\n",
      "win              O      | O\n",
      ",                O      | O\n",
      "china            B-PER  | B-LOC\n",
      "in               O      | O\n",
      "surprise         O      | O\n",
      "defeat           O      | O\n",
      ".                O      | O\n",
      "_PAD_            O      | O\n",
      "_PAD_            O      | O\n",
      "_PAD_            O      | O\n",
      "_PAD_            O      | O\n",
      "_PAD_            O      | O\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "sentence = X_sent_test[i]\n",
    "y_pred = model.predict({'char_encoding': X_char_test, 'word_encoding': X_sent_test})\n",
    "y_pred = y_pred[i]\n",
    "y_true = Y_test[i]\n",
    "\n",
    "print('      TOKEN      TRUE Y | PRED Y')\n",
    "print('='*34)\n",
    "for idx in range(len(sentence[:15])):\n",
    "    print(f'{token_tokenizer.index_word[sentence[idx]]:15}  {idx2tag[y_true[idx]]:6} | {idx2tag[y_pred[idx]]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Glove+CNN+BiLSTM+CRF_CoNLL.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
