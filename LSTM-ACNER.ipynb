{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM on Annotated Corpus for Named Entity Recognition\n",
    "\n",
    "In this notebook, we perform Entity Extraction on the ACNER dataset using a LSTM-based neural network. We use `tf.keras.preprocessing.text.Tokenizer` for text preprocessing, we pad all the santences to the same length and load Glove embeddings for token encoding, then we use `tensorflow.keras` to build the model. Evaluation is made with the `seqeval` package.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from utils import dataio, kerasutils, modelutils\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from seqeval.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "The dataset can be found [here](https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus). It reports a lot of features for each token, but we only keep the token string and the entity tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 281837: expected 25 fields, saw 34\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter level: sentence_only\n",
      "Dataset dimension: 35177 sentences\n",
      "Data read successfully!\n"
     ]
    }
   ],
   "source": [
    "raw, ner, output_labels = dataio.load_anerd_data(\n",
    "    os.path.join('data', 'annotated-ner-dataset', 'ner.csv'),\n",
    "    filter_level='sentence_only'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: {'B-gpe', 'B-nat', 'I-geo', 'B-per', 'B-tim', 'I-org', 'B-geo', 'I-art', 'unk', 'O', 'I-gpe', 'B-eve', 'I-eve', 'I-nat', 'I-per', 'B-art', 'B-org', 'I-tim'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Labels:\", output_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Example:\n",
      "Thousands       | O\n",
      "of              | O\n",
      "demonstrators   | O\n",
      "have            | O\n",
      "marched         | O\n",
      "through         | O\n",
      "London          | B-geo\n",
      "to              | O\n",
      "protest         | O\n",
      "the             | O\n",
      "war             | O\n",
      "in              | O\n",
      "Iraq            | B-geo\n",
      "and             | O\n",
      "demand          | O\n",
      "the             | O\n",
      "withdrawal      | O\n",
      "of              | O\n",
      "British         | B-gpe\n",
      "troops          | O\n",
      "from            | O\n",
      "that            | O\n",
      "country         | O\n",
      ".               | O\n",
      "Thousands       | O\n",
      "of              | O\n",
      "demonstrators   | O\n",
      "have            | O\n",
      "marched         | O\n",
      "through         | O\n",
      "London          | B-geo\n",
      "to              | O\n",
      "protest         | O\n",
      "the             | O\n",
      "war             | O\n",
      "in              | O\n",
      "Iraq            | B-geo\n",
      "and             | O\n",
      "demand          | O\n",
      "the             | O\n",
      "withdrawal      | O\n",
      "of              | O\n",
      "British         | B-gpe\n",
      "troops          | O\n",
      "from            | O\n",
      "that            | O\n",
      "country         | O\n",
      ".               | O\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentence Example:\")\n",
    "for i in range(len(raw[0])):\n",
    "    print(f'{raw[0][i]:15} | {ner[0][i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text preprocessing and token encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integer encoding of tokens\n",
    "token_tokenizer = Tokenizer()    # Automatically lowers tokens\n",
    "token_tokenizer.fit_on_texts(raw)\n",
    "sequences = token_tokenizer.texts_to_sequences(raw)\n",
    "\n",
    "# Dictionaries for id <-> string conversation of labels\n",
    "tag2idx = { tag: idx for idx, tag in enumerate(output_labels) }\n",
    "idx2tag = { idx: tag for tag, idx in tag2idx.items() }\n",
    "\n",
    "# Label encoding\n",
    "ner_sequences = [[tag2idx[tag] for tag in sentence] for sentence in ner]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[259, 5, 902, 15, 1950, 245, 482, 6, 492, 1, 134, 4, 59, 8, 640, 1, 799, 5, 182, 91, 21, 14, 54, 2, 259, 5, 902, 15, 1950, 245, 482, 6, 492, 1, 134, 4, 59, 8, 640, 1, 799, 5, 182, 91, 21, 14, 54, 2]\n",
      "   259 : thousands\n",
      "     5 : of\n",
      "   902 : demonstrators\n",
      "    15 : have\n",
      "  1950 : marched\n",
      "   245 : through\n",
      "   482 : london\n",
      "     6 : to\n",
      "   492 : protest\n",
      "     1 : the\n",
      "   134 : war\n",
      "     4 : in\n",
      "    59 : iraq\n",
      "     8 : and\n",
      "   640 : demand\n",
      "     1 : the\n",
      "   799 : withdrawal\n",
      "     5 : of\n",
      "   182 : british\n",
      "    91 : troops\n",
      "    21 : from\n",
      "    14 : that\n",
      "    54 : country\n",
      "     2 : .\n",
      "   259 : thousands\n",
      "     5 : of\n",
      "   902 : demonstrators\n",
      "    15 : have\n",
      "  1950 : marched\n",
      "   245 : through\n",
      "   482 : london\n",
      "     6 : to\n",
      "   492 : protest\n",
      "     1 : the\n",
      "   134 : war\n",
      "     4 : in\n",
      "    59 : iraq\n",
      "     8 : and\n",
      "   640 : demand\n",
      "     1 : the\n",
      "   799 : withdrawal\n",
      "     5 : of\n",
      "   182 : british\n",
      "    91 : troops\n",
      "    21 : from\n",
      "    14 : that\n",
      "    54 : country\n",
      "     2 : .\n"
     ]
    }
   ],
   "source": [
    "print(sequences[0])\n",
    "for i in sequences[0]:\n",
    "    print(f'{i:6} : {token_tokenizer.index_word[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary dimension: 27419\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = len(token_tokenizer.word_counts)\n",
    "print('Vocabulary dimension:', vocabulary_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequence Padding\n",
    "\n",
    "The input sequence of an LSTM model must have a fixed length. We choose the most appropriate seqence length given the length of the sentences of the dataset, than we PAD shorter sentences and truncate the longer ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest sequence: 140\n",
      "[('75%', 38.0), ('80%', 42.0), ('85%', 47.0), ('90%', 52.0), ('95%', 62.0), ('100%', 140.0)]\n"
     ]
    }
   ],
   "source": [
    "sequence_len = np.array([len(s) for s in sequences])\n",
    "longest_sequence = sequence_len.max()\n",
    "print(f'Longest sequence: {longest_sequence}')\n",
    "\n",
    "print([(str(p)+'%', np.percentile(sequence_len, p)) for p in range(75,101, 5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tags = len(output_labels); n_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 60\n",
    "X = pad_sequences(sequences, maxlen=max_len, padding='post', truncating='post')\n",
    "y = pad_sequences(ner_sequences, maxlen=max_len, value=tag2idx['O'], \n",
    "                  padding='post', truncating='post')\n",
    "\n",
    "# Convert labels from ids to one-hot vectors\n",
    "y = to_categorical(y, num_classes=n_tags, dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_tokenizer.index_word[0] = '_PAD_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35177, 60)\n",
      "(35177, 60, 18)\n"
     ]
    }
   ],
   "source": [
    "# Final training set dimensionalities\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "The function that loads Glove embedding and the function which creates the LSTM model can be found in the `utils/kerasutils.py` module. Training stopping criterion is Early Stopping with patience on the loss value on validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GLOVE=True      # Choose if you want to use Glove pretrained embeddings or \n",
    "                    # to train an Embedding from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400001 word vectors.\n"
     ]
    }
   ],
   "source": [
    "glove_matrix=None\n",
    "if USE_GLOVE:\n",
    "    glove_embedding_path = os.path.join('embeddings', 'glove.6B.100d.txt')\n",
    "    embedding_dim = 100\n",
    "    glove_matrix = kerasutils.load_glove_embedding_matrix(\n",
    "        glove_embedding_path, \n",
    "        token_tokenizer.word_index, \n",
    "        embedding_dim\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 60, 100)           2742000   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 60, 100)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 60, 400)           481600    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 60, 18)            7218      \n",
      "=================================================================\n",
      "Total params: 3,230,818\n",
      "Trainable params: 3,230,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = kerasutils.create_paper_BiLSTM(vocabulary_size+1, max_len, \n",
    "                                       len(output_labels), \n",
    "                                       use_glove=USE_GLOVE, \n",
    "                                       glove_matrix=glove_matrix)\n",
    "\n",
    "# Early stopping\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0.01,\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2252/2252 [==============================] - 184s 82ms/step - loss: 0.1310 - accuracy: 0.9255 - precision: 0.9449 - recall: 0.9084 - val_loss: 0.0732 - val_accuracy: 0.9547 - val_precision: 0.9622 - val_recall: 0.9488\n",
      "Epoch 2/20\n",
      "2252/2252 [==============================] - 178s 79ms/step - loss: 0.0799 - accuracy: 0.9511 - precision: 0.9615 - recall: 0.9426 - val_loss: 0.0636 - val_accuracy: 0.9597 - val_precision: 0.9656 - val_recall: 0.9551\n",
      "Epoch 3/20\n",
      "2252/2252 [==============================] - 180s 80ms/step - loss: 0.0677 - accuracy: 0.9573 - precision: 0.9656 - recall: 0.9509 - val_loss: 0.0611 - val_accuracy: 0.9616 - val_precision: 0.9666 - val_recall: 0.9578\n",
      "Epoch 4/20\n",
      "2252/2252 [==============================] - 179s 80ms/step - loss: 0.0606 - accuracy: 0.9610 - precision: 0.9684 - recall: 0.9554 - val_loss: 0.0591 - val_accuracy: 0.9619 - val_precision: 0.9668 - val_recall: 0.9585\n",
      "Epoch 5/20\n",
      "2252/2252 [==============================] - 179s 80ms/step - loss: 0.0560 - accuracy: 0.9639 - precision: 0.9702 - recall: 0.9589 - val_loss: 0.0575 - val_accuracy: 0.9634 - val_precision: 0.9675 - val_recall: 0.9607\n",
      "Epoch 6/20\n",
      "2252/2252 [==============================] - ETA: 0s - loss: 0.0520 - accuracy: 0.9657 - precision: 0.9714 - recall: 0.9611Restoring model weights from the end of the best epoch.\n",
      "2252/2252 [==============================] - 180s 80ms/step - loss: 0.0520 - accuracy: 0.9657 - precision: 0.9714 - recall: 0.9611 - val_loss: 0.0575 - val_accuracy: 0.9636 - val_precision: 0.9675 - val_recall: 0.9610\n",
      "Epoch 00006: early stopping\n",
      "Wall time: 18min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_size = 10\n",
    "history = model.fit(\n",
    "    X_train, y_train, \n",
    "    batch_size=batch_size, \n",
    "    epochs=20, \n",
    "    validation_split=0.2, \n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Evaluation\n",
    "We evaluate three aspects of the model:\n",
    "* **Memory consumption** using the `kerasutils.print_model_memory_usage()` function (found [here](https://stackoverflow.com/questions/43137288/how-to-determine-needed-memory-of-keras-model));\n",
    "* **Latency in prediction** using the function `time.process_time()`;\n",
    "* **F1-score** _on entities_ on the test set using `seqeval`;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 13.739 MB\n"
     ]
    }
   ],
   "source": [
    "kerasutils.print_model_memory_usage(batch_size, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model latency in prediction: 0.00476 s\n"
     ]
    }
   ],
   "source": [
    "print(f'Model latency in prediction: {modelutils.compute_prediction_latency(X_test, model):.3} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set\n",
      "           precision    recall  f1-score   support\n",
      "\n",
      "      per      0.748     0.797     0.772     13596\n",
      "      geo      0.820     0.895     0.856     29297\n",
      "      org      0.686     0.549     0.610     15970\n",
      "      gpe      0.954     0.924     0.939     12914\n",
      "      tim      0.838     0.880     0.858     15898\n",
      "      eve      0.374     0.367     0.371       267\n",
      "      art      0.761     0.099     0.175       355\n",
      "      nat      0.439     0.307     0.361       176\n",
      "\n",
      "micro avg      0.809     0.813     0.811     88473\n",
      "macro avg      0.805     0.813     0.806     88473\n",
      "\n",
      "\n",
      "\n",
      "Test Set\n",
      "           precision    recall  f1-score   support\n",
      "\n",
      "      per      0.728     0.782     0.754      3265\n",
      "      tim      0.823     0.850     0.836      3987\n",
      "      geo      0.807     0.879     0.842      7580\n",
      "      gpe      0.956     0.926     0.941      3260\n",
      "      org      0.661     0.528     0.587      3950\n",
      "      eve      0.262     0.250     0.256        68\n",
      "      nat      0.214     0.122     0.156        49\n",
      "      art      0.333     0.028     0.052        71\n",
      "\n",
      "micro avg      0.796     0.798     0.797     22230\n",
      "macro avg      0.790     0.798     0.791     22230\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasets = [('Training Set', X_train, y_train), ('Test Set', X_test, y_test)]\n",
    "\n",
    "for title, X, Y in datasets:\n",
    "    # Get predictions: for each token we have as prediction a vector \n",
    "    # of probabilites\n",
    "    Y_pred = model.predict(X, batch_size=batch_size)\n",
    "    # We choose as category the one with the highest probability\n",
    "    Y_pred = np.array(np.argmax(Y_pred, axis=-1))\n",
    "    # Also flatten true labels\n",
    "    Y = np.array(np.argmax(Y, axis=-1))\n",
    "    # Remove padding from predictions and labels\n",
    "    Y, Y_pred = kerasutils.remove_seq_padding(X, Y, Y_pred)\n",
    "    # Restore strings instead that entity idss\n",
    "    Y, Y_pred = modelutils.from_encode_to_literal_labels(Y, Y_pred, idx2tag)\n",
    "    \n",
    "    print(title)\n",
    "    print(classification_report(Y, Y_pred, digits=3))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
